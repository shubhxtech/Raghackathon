# RAG Pipeline for Multihop Query Dataset

## Project Overview

This repository contains a Retrieval-Augmented Generation (RAG) pipeline designed to answer user queries using a multi-hop dataset, where the answers require evidence from multiple documents (2 to 4). The pipeline processes a corpus of documents, retrieves relevant chunks, and returns a structured JSON output similar to `train.json`.

### Problem Statement

The goal is to develop a RAG pipeline capable of answering queries that require multi-hop reasoning over different documents, sometimes using metadata from the documents to provide a complete answer. The pipeline generates responses in the following format:

- **query**: The question posed to the system.
- **answer**: The inferred response based on evidence from the corpus.
- **question_type**: Classification of the type of question, such as "inference_query."
- **evidence_list**: A list of sources with the following details:
  - **title**: Title of the document.
  - **author**: Author of the source.
  - **url**: Link to the document.
  - **source**: Name of the publisher or website.
  - **category**: The category (e.g., technology, business).
  - **published_at**: Publication date.
  - **fact**: Extracted piece of evidence supporting the answer.

### Approach

1. **Chunking and Embedding**:
   - The data is chunked into two-sentence segments using a chunking function.
   - Each chunk is embedded using the `all-MiniLM-L12-v2` model to encode the text.
   
2. **Retrieving Relevant Chunks**:
   - Cosine similarity is computed between the query embedding and the chunk embeddings.
   - The most relevant chunks are retrieved, provided their cosine similarity score is above 0.5. If the score is lower, the system returns an "Insufficient answer" response.

3. **Summarization**:
   - Relevant chunks are summarized using the `facebook/bart-large-cnn` model to create a concise answer.

4. **Question Answering**:
   - The `distilbert-base-cased-distilled-squad` model is used to answer specific questions based on the retrieved chunks.

5. **Question Type Classification**:
   - A CNN model classifies the question type (e.g., "inference_query").

6. **Yes/No Classification**:
   - The `facebook/bart-large-mnli` model classifies yes/no-type questions.

7. **Hosting**:
   - The pipeline is hosted using ngrok to allow communication between the Colab environment and the front end, passing JSON-formatted data.

### Output Format

The output of the pipeline is a structured JSON file containing:

```json
{
  "query": "User's query",
  "answer": "Generated answer",
  "question_type": "inference_query",
  "evidence_list": [
    {
      "title": "Document title",
      "author": "Author name",
      "url": "Document URL",
      "source": "Publication name",
      "category": "Document category",
      "published_at": "Publication date",
      "fact": "Relevant fact from the document"
    }
  ]
}
```
## Models Used

- **Summarization**: `facebook/bart-large-cnn`
- **Question Answering**: `distilbert-base-cased-distilled-squad`
- **Question Type Classification**: Custom CNN model
- **Yes/No Classification**: `facebook/bart-large-mnli`
- **Embedding**: `sentence-transformers/all-MiniLM-L12-v2`

## Hosting and Deployment

The server is hosted using **ngrok**, enabling communication between the RAG pipeline backend (running in Colab) and the front end. This setup facilitates the seamless transfer of JSON-formatted responses generated by the pipeline.



## How to Use

### Prerequisites:
1. **Node.js**: Ensure you have Node.js installed on your machine. Download it from [here](https://nodejs.org/).
2. **Google Colab Account**: You will need a Google Colab account to run the Jupyter notebook for the RAG pipeline. Create one [here](https://colab.research.google.com/).

### Steps to Run the Project:

#### 1. Clone the GitHub Repository:
Clone the repository to your local machine using the following command:
```bash
git clone https://github.com/shubhxtech/Raghackathon.git
```

#### 2. Open and Run the Jupyter Notebook on Google Colab:
- Upload the provided Jupyter notebook (`pipeline_notebook.ipynb`) to your Google Colab.
- Run the notebook. It may take approximately 5 minutes to load all the necessary models and dependencies.

#### 3. Copy the ngrok Link:
- Once the notebook finishes running, you will see an ngrok link in the last cell of the notebook.
- Copy the link (it will look something like `https://xxxxxx.ngrok.io`).

#### 4. Paste the ngrok Link in the Frontend:
- In the cloned repository, open the `chat.jsx` file located in the `frontend` folder.
- Replace the placeholder URL in the `chat.jsx` file with the ngrok link you copied from Colab.

#### 5. Start the Frontend:
- Navigate to the `frontend` folder in the terminal and run the following commands to start the frontend:
  ```bash
  npm install
  npm start
